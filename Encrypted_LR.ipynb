{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# With CKKS encrypted linear regression\n",
    "\n",
    "The plaintext and encrypted linear regression are implemented to simulate the exemplary use case one in the main report.\n",
    "\n",
    "The encrypted linear regression follows the code from the plain linear regression, which is based on the exercises of the ADML module by Solange Emmenegger (Solange Emmenegger, Hochschule Luzern, Module Advanced Machine Learning, accessed on 19 April 2024 at https://gitlab.renku.hslu.ch/solange.emmenegger/ml-adml-hslu/-/tree/master/notebooks/03A%20Supervised%20Learning, and https://gitlab.renku.hslu.ch/solange.emmenegger/ml-adml-hslu/-/blob/master/notebooks/04B%20Gradient%20Descent/Gradient%20Descent.ipynb).\n",
    "\n",
    "The dataset Apartment rental offers in Germany from kaggle (https://www.kaggle.com/datasets/corrieaar/apartment-rental-offers-in-germany) is used with a similar implementation as the linear regression. The main difference with the plaintext linear regression is that CKKS encrypted tensors and operations are used to train the linear regression on encrypted data and division operations are pre-computed.\n",
    "\n",
    "Firstly, the libraries are imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from time import time\n",
    "import psutil\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict\n",
    "\n",
    "import tenseal as ts\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data cleaning\n",
    "\n",
    "In this section, the dataset is prepared for processing. The following actions are performed:\n",
    "\n",
    "- Amount of features reduced\n",
    "- Data converted to appropriate datatypes\n",
    "- Unsensical data is removed\n",
    "- NA values are removed\n",
    "- Outliers are removed as linear regression is sensitive to outliers\n",
    "- Categorical data is converted to numeric data\n",
    "- The data is split into a train and test set\n",
    "- The data is scaled as linear regression is sensitive to data ranges.\n",
    "\n",
    "The code leans on the exercises from the module ADML (https://gitlab.renku.hslu.ch/solange.emmenegger/ml-adml-hslu/-/tree/master/notebooks/03A%20Supervised%20Learning)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"immo_data.csv\")\n",
    "\n",
    "columns_to_drop = ['serviceCharge', 'telekomTvOffer', 'noParkSpaces', 'pricetrend','regio3', 'heatingType', 'telekomUploadSpeed', 'telekomHybridUploadSpeed', 'lastRefurbish', 'newlyConst', 'picturecount', 'firingTypes', 'hasKitchen', 'geo_bln','cellar', 'yearConstructedRange', 'baseRent', 'houseNumber', 'geo_krs', 'interiorQual', 'petsAllowed', 'street', 'streetPlain', 'baseRentRange', 'geo_plz', 'thermalChar', 'floor', 'numberOfFloors', 'noRoomsRange', 'garden', 'livingSpaceRange', 'description', 'facilities', 'heatingCosts', 'energyEfficiencyClass', 'electricityBasePrice', 'electricityKwhPrice', 'date' ]\n",
    "df = df.drop(columns=columns_to_drop, axis=1)\n",
    "df['regio1'] = df.regio1.astype('category')\n",
    "df['regio2'] = df.regio1.astype('category')\n",
    "df['balcony'] = df['balcony'].astype(int)\n",
    "df['lift'] = df['lift'].astype(int)\n",
    "df['condition'] = df.condition.astype('category')\n",
    "df['typeOfFlat'] = df.typeOfFlat.astype('category')\n",
    "df = df.dropna()\n",
    "df = df[(df['totalRent'] != 0) & (df['livingSpace'] != 0) & (df['yearConstructed'] > 1940) & (df['yearConstructed'] < 2021)]\n",
    "numerical_cols = ['totalRent', 'yearConstructed', 'livingSpace', 'noRooms']\n",
    "# Remove outliers\n",
    "q3 = df.loc[:, numerical_cols].describe().loc['75%']\n",
    "iqr = q3 - df.loc[:, numerical_cols].describe().loc['25%']\n",
    "upper_boundary = q3 + 1.5*iqr\n",
    "upper_boundary\n",
    "\n",
    "df = df[(df.totalRent <= upper_boundary.totalRent) &\n",
    "        (df.yearConstructed <= upper_boundary.yearConstructed) &\n",
    "        (df.livingSpace <= upper_boundary.livingSpace) &\n",
    "         (df.noRooms <= upper_boundary.noRooms) ]\n",
    "\n",
    "df = pd.concat([df, pd.get_dummies(df.regio1)], axis='columns')\n",
    "df = pd.concat([df, pd.get_dummies(df.regio2)], axis='columns')\n",
    "df = pd.concat([df, pd.get_dummies(df.condition)], axis='columns')\n",
    "df = pd.concat([df, pd.get_dummies(df.typeOfFlat)], axis='columns')\n",
    "df.drop('regio1', axis='columns', inplace=True)\n",
    "df.drop('regio2', axis='columns', inplace=True)\n",
    "df.drop('condition', axis='columns', inplace=True)\n",
    "df.drop('typeOfFlat', axis='columns', inplace=True)\n",
    "df.drop(['scoutId'], axis='columns', inplace=True)\n",
    "\n",
    "train_rents, test_rents = train_test_split(df, test_size=0.4, random_state=42, shuffle=True)\n",
    "scaler = StandardScaler()\n",
    "train_rents = pd.DataFrame(scaler.fit_transform(train_rents), columns=train_rents.columns, index=train_rents.index)\n",
    "test_rents = pd.DataFrame(scaler.transform(test_rents), columns=test_rents.columns, index=test_rents.index)\n",
    "X_train_rents = train_rents.drop(columns=[\"totalRent\"]).values\n",
    "X_test_rents = test_rents.drop(columns=[\"totalRent\"]).values\n",
    "y_train_rents = train_rents.totalRent.values\n",
    "y_test_rents = test_rents.totalRent.values\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the TenSEAL context\n",
    "\n",
    "In order to use homomorphic encryption, Tenseal context with encryption parameters is defined. For the purposes of the training, we choose the polynomial degree of 8192, the coefficient modulus bitsizes of [40, 21, 21, 21, 21, 40] and the global scale as 21. The author identifies these criteria by testing whether the TenSEAL library causes an error, because the ciphertext starts to exceed the scale or the size of the ciphertext exceeds the RAM capabilities. The author chose the asymmetric version of CKKS, which has important practical applications due to its public key nature. \n",
    "\n",
    "The polynomial modulus degree (poly_modulus_degree) has the following influence: (taken from https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%202%20-%20Working%20with%20Approximate%20Numbers.ipynb, full reference below)\n",
    "- It changes the number of coefficients in the plaintext polynomials\n",
    "- It affects size of the ciphertext elements\n",
    "- The bigger it is, the worse the computation performance of the scheme is\n",
    "- The bigger it is, the better is the security level\n",
    "\n",
    "The coefficient modulus has an influence on: (taken from https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%202%20-%20Working%20with%20Approximate%20Numbers.ipynb, full reference below)\n",
    "- The size of the ciphertext elements\n",
    "- The length of the list determines the number of encrypted multiplications supported\n",
    "- The bigger the modulus sizes are, the worse the security is \n",
    "\n",
    "The global scale is a scaling factor that affects the encoding of the binary representation of numbers. (taken from https://github.com/OpenMined/TenSEAL/blob/main/tutorials/Tutorial%202%20-%20Working%20with%20Approximate%20Numbers.ipynb, full reference below)\n",
    "\n",
    "The code is based as mentioned on the code from the ADML module from Hochschule Luzern as well as on the tutorials provided by the contibutors to the TenSEAL library (Ayoub Benaissa and Bilal Retiat and Bogdan Cebere and Alaa Eddine Belfedhal, TenSEAL: A Library for Encrypted Tensor Operations Using Homomorphic Encryption, 2021, 2104.03152m arXiV, visited at https://github.com/OpenMined/TenSEAL/tree/main/tutorials on 1 May 2024)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context():\n",
    "    # parameters\n",
    "    poly_mod_degree = 8192\n",
    "    coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 40]\n",
    "    enc_type = ts.ENCRYPTION_TYPE.ASYMMETRIC\n",
    "    # create TenSEALContext\n",
    "    context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes, encryption_type=enc_type)\n",
    "    context.global_scale = 2 ** 21\n",
    "    context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "context = context()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypt the data\n",
    "\n",
    "The following function encrypts the plaintext data, cleaned above, into CKKS tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_trainset_tensor(X, y):    \n",
    "\n",
    "    enc_x_train = ts.ckks_tensor(context, X)\n",
    "    enc_y_train = ts.ckks_tensor(context, y)\n",
    "\n",
    "    return enc_x_train, enc_y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean squared error function\n",
    "\n",
    "The following function implements the mean squared error as with the plaintext model. It is used to measure the performance of the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cost(y, y_pred):\n",
    "    cost = np.sum(np.square(y - y_pred))/ (2 * len(y))\n",
    "    return cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted predict function\n",
    "\n",
    "The encrypted predict function performs the predict with linear regression on encrypted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_predict(enc_X, bias, thetas):\n",
    "    return enc_X.dot(thetas) + bias\n",
    "\n",
    "# The non encrypted predict is only used for measurement\n",
    "def predict(X, bias, thetas):\n",
    "    y_pred = bias + np.dot(X, thetas)\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted gradient function\n",
    "\n",
    "The function below implement the gradient calculation of the linear regression with encrypted operations. The N parameter is the reciprocal of the length of X. This is necessary as TenSEAL does not implement division."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_gradient(X, y, bias, thetas, N):\n",
    "    diff = enc_predict(X, bias, thetas) - y\n",
    "\n",
    "    grad_bias = diff.sum() * N\n",
    "    grad_thetas = diff.dot(X) * N\n",
    "    return grad_bias, grad_thetas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is a decryption helper function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decrypt(data, context):\n",
    "    return data.decrypt(context.secret_key()).tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encrypted training function with minibatches\n",
    "\n",
    "The following function trains the parameters of the encrypted linear regression. Note that the thetas and bias are decrypted after each step in order to avoid deepening the ciphertext and increase its size. With the available resources in this project, decrypting the thetas and bias was attempted at the epoch level, however, the author does not possess enough RAM on his computing environments to perform the encrypted gradient function with thetas and bias as encrypted tensors. The bottom line is that decryption of the gradient has to occur in any case during the training.\n",
    "\n",
    "In a practical situation, the encrypted thetas and the bias below have to be send over the network back to the owner of the data for decryption, which holds the secret key. The owner of the data thereafter decrypts and sends the unencrypted thetas and bias back to the owner of the model in order to proceed with the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient descent training\n",
    "\n",
    "The next function performs the gradient descent training. It is build on the code from the plaintext linear regression, with the addition that it encrypts batches from the dataset and uses it in gradient descent. It also decrypts the gradients in each iteration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_fit_minibatch(X_train, y_train, alpha, num_epochs, reciprocal_N, batch_size, display_every=50):\n",
    "    number_features = X_train.shape[1]\n",
    "    bias = 0.0\n",
    "    thetas = np.random.randn(*(1, number_features )).reshape(-1)\n",
    "    num_samples = len(X_train)\n",
    "    indices_train = np.arange(len(X_train))\n",
    "    \n",
    "    steps = int(num_samples/batch_size)\n",
    "\n",
    "    hist = defaultdict(list)\n",
    "    for epoch in tqdm(range(1, num_epochs+1)):\n",
    "        # Shuffles the data\n",
    "        np.random.shuffle(indices_train)\n",
    "        \n",
    "        X_train_epoch = X_train[indices_train]\n",
    "        y_train_epoch = y_train[indices_train]\n",
    "\n",
    "        for step in range(steps):\n",
    "            # Create batch slices\n",
    "            start = step * batch_size\n",
    "            end = step * batch_size + batch_size\n",
    "            # Slices the data into mini batches\n",
    "            X_train_mini = X_train_epoch[start:end]\n",
    "            y_train_mini = y_train_epoch[start:end]\n",
    "            # Encrypt the minibatch, this would take place at the owner of the data and then may be transferred over the network. The data can also be encrypted prior to the training in a binary file. Due to the focus on the computation overhead, the data is encrypted during training\n",
    "            enc_x_train, enc_y_train = encrypt_trainset_tensor(X_train_mini, y_train_mini)\n",
    "\n",
    "            grad_bias, grad_thetas = enc_gradient(enc_x_train, enc_y_train, bias, thetas, reciprocal_N)\n",
    "            # The decryption of the grad_bias and grad_thetas has to be performed at the owner of the data who has the secret key\n",
    "            # Not decrypting the data would require to deepen the cipher and significatly increase the ciphertext size, requiring more computation resources\n",
    "            # Parameters bias and thetas are updated\n",
    "            bias = bias - alpha * np.array(grad_bias.decrypt().tolist())\n",
    "            thetas = thetas - alpha * np.array(grad_thetas.decrypt().tolist())\n",
    "\n",
    "        # This part of the code servers only to log the performance during each epoch and is not necessary in a practical situation\n",
    "        y_pred_train = predict(X_train_epoch, bias, thetas)\n",
    "        train_cost = np.array(cost(y_train_epoch, y_pred_train))\n",
    "        train_r2 = np.array(r2_score(y_train_epoch, y_pred_train))\n",
    "        \n",
    "        hist[\"train_cost\"].append(train_cost)\n",
    "        hist[\"train_r2\"].append(train_r2)\n",
    "        \n",
    "        if epoch % display_every == 0:\n",
    "            print(\"Epoch {0} - cost: {1:.2} - r2: {2:.4}\"\n",
    "                .format(epoch, train_cost, train_r2))\n",
    "        \n",
    "    return bias, thetas, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the dataset is sliced in order to prevent the training to run for days. The size of 10000 data samples has been chosen to perform the evaluation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_taken = 10000\n",
    "batch_size = 100\n",
    "reciprocal_N = 1 / batch_size\n",
    "\n",
    "alpha = 0.01\n",
    "num_epochs = 6\n",
    "\n",
    "# measure time\n",
    "t_start = time()\n",
    "# measure resource usage\n",
    "mem_usage = psutil.Process().memory_info().rss\n",
    "enc_bias, enc_thetas, hist_rent_enc = enc_fit_minibatch(X_train_rents[:len_taken], y_train_rents[:len_taken], alpha, num_epochs, reciprocal_N, batch_size)\n",
    "mem_usage_end = psutil.Process().memory_info().rss\n",
    "\n",
    "# Calculate the differences\n",
    "mem_diff = mem_usage_end - mem_usage\n",
    "t_end = time()\n",
    "print(f\"Training of the Linear Regression took {int(t_end - t_start)} seconds\")\n",
    "print(f\"Memory usage difference: {mem_diff} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the trained encrypted linear regression is evaluated on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_rents = predict(X_test_rents, enc_bias, enc_thetas)\n",
    "r2 = r2_score(y_test_rents, y_pred_rents)\n",
    "print(\"R2:\", r2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training of the linear regression model with data read from a file (not evaluated)\n",
    "\n",
    "To provide a glimpse into the case, how long a linear regression model would have to be trained while reading the encrypted data from a file, modified functions are presented that enable this. Again, this is not the proof of concept subject to evaluation.\n",
    "\n",
    "Firstly, the context is defined. Thereafter, a public context is created by removing the secret key and writing it to a binary file. This binary file would be provided to MLco in the hypothetical scenario. The code is based on the tests from and TenSEAL library (Ayoub Benaissa and Bilal Retiat and Bogdan Cebere and Alaa Eddine Belfedhal, TenSEAL: A Library for Encrypted Tensor Operations Using Homomorphic Encryption, 2021, 2104.03152m arXiV, visited on 18 May 2024 at https://github.com/OpenMined/TenSEAL/blob/main/tests/python/tenseal/tensors/test_serialization.py) and suggestions from ChatGPT (“How can I efficiently write serialized CKKS vectors into a file?”, ChatGPT (GPT-4o), OpenAI, generated on 18 May 2024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def context():\n",
    "    # parameters\n",
    "    poly_mod_degree = 8192\n",
    "    coeff_mod_bit_sizes = [40, 21, 21, 21, 21, 40]\n",
    "    enc_type = ts.ENCRYPTION_TYPE.ASYMMETRIC\n",
    "    # create TenSEALContext\n",
    "    context = ts.context(ts.SCHEME_TYPE.CKKS, poly_mod_degree, -1, coeff_mod_bit_sizes, encryption_type=enc_type)\n",
    "    context.global_scale = 2 ** 21\n",
    "    context.generate_galois_keys()\n",
    "    return context\n",
    "\n",
    "\n",
    "context = context()\n",
    "public_context = context.copy()\n",
    "public_context.make_context_public()\n",
    "\n",
    "# save the context with the public key only for transmission to MLco.\n",
    "with open(\"public_context.bin\", 'wb') as pub_file:\n",
    "    pub_file.write(public_context.serialize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encrypt data and write it in batches to a binary file function\n",
    "\n",
    "The following function encrypts the data in batches and then writes into a binary file. This is the encrypted data that is provided to MLco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encrypt_and_serialize_batches(data_X, data_y, batch_size, filename, context):\n",
    "    num_samples = data_X.shape[0]\n",
    "    indices = np.arange(num_samples)\n",
    "    np.random.shuffle(indices)\n",
    "    data_X = data_X[indices]\n",
    "    data_y = data_y[indices]\n",
    "    \n",
    "    with open(filename, 'wb') as file:\n",
    "        for start in range(0, num_samples, batch_size):\n",
    "            end = min(start + batch_size, num_samples)\n",
    "            data_batch_X = data_X[start:end]\n",
    "            data_batch_y = data_y[start:end]\n",
    "            \n",
    "            # Encrypt the batch\n",
    "            enc_train_X = ts.ckks_tensor(context, data_batch_X)\n",
    "            enc_train_y = ts.ckks_tensor(context, data_batch_y)\n",
    "            \n",
    "            # Serialize the encrypted tensors\n",
    "            serialized_batch_X = enc_train_X.serialize()\n",
    "            serialized_batch_y = enc_train_y.serialize()\n",
    "            \n",
    "            # Write the length of the serialized data and the data itself\n",
    "            file.write(len(serialized_batch_X).to_bytes(4, byteorder='big'))\n",
    "            file.write(serialized_batch_X)\n",
    "            file.write(len(serialized_batch_y).to_bytes(4, byteorder='big'))\n",
    "            file.write(serialized_batch_y)\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read and decrypt data function\n",
    "\n",
    "Deserialize_decrypt_next_batch function reads the batches from the file one at a time and returns them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deserialize_decrypt_next_batch(file, context):\n",
    "    len_x_bytes = file.read(4)\n",
    "    if not len_x_bytes:\n",
    "        return None, None\n",
    "\n",
    "    len_x = int.from_bytes(len_x_bytes, byteorder='big')\n",
    "    serialized_batch_X = file.read(len_x)\n",
    "    \n",
    "    len_y_bytes = file.read(4)\n",
    "    len_y = int.from_bytes(len_y_bytes, byteorder='big')\n",
    "    serialized_batch_y = file.read(len_y)\n",
    "    \n",
    "    enc_train_X = ts.ckks_tensor_from(context, serialized_batch_X)\n",
    "    enc_train_y = ts.ckks_tensor_from(context, serialized_batch_y)\n",
    "    \n",
    "    return enc_train_X, enc_train_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encryption of the data\n",
    "\n",
    "Before providing the data to MLco, the data is encrypted by SRE. WARNING, this will create a file of size 170 GB. The data and the public context is then provided to MLco."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encrypt_and_serialize_batches(X_train_rents[:10000], y_train_rents[:10000], 100, \"enc_dataframe.bin\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the context for the data owner and the data user\n",
    "\n",
    "The data user is MLco. MLco receives the public context that only contains the public key. The public context is necessary to reestablish the CKKS vectors from the binary file as packed by SRE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"public_context.bin\", 'rb') as pub_file:\n",
    "    serialized_public_context = pub_file.read()\n",
    "\n",
    "public_context = ts.context_from(serialized_public_context)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modified gradient descent function\n",
    "\n",
    "Below, we modify the gradient descent function to read batches from the a binary file instead of encrypting the data during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enc_fit_minibatch_readfile(X_train, y_train, alpha, num_epochs, batch_size, file, public_context, context, display_every=1):\n",
    "    number_features = X_train.shape[1]\n",
    "    bias = 0.0\n",
    "    thetas = np.random.randn(*(1, number_features )).reshape(-1)\n",
    "    reciprocal_N = 1 / batch_size\n",
    "    \n",
    "    hist = defaultdict(list)\n",
    "\n",
    "    for epoch in tqdm(range(1, num_epochs + 1)):\n",
    "        # Here is noted that shuffling during the training is not possible as the data is already encrypted in batches\n",
    "        with open(file, 'rb') as f:\n",
    "            while True:\n",
    "                X_train_iteration, y_train_iteration = deserialize_decrypt_next_batch(f, public_context)\n",
    "                if X_train_iteration is None:\n",
    "                    break\n",
    "                grad_bias, grad_thetas = enc_gradient(X_train_iteration, y_train_iteration, bias, thetas, reciprocal_N)\n",
    "                \n",
    "                # Decrypt the gradients (occurs at the data owner, SRE, as MLco does not have the secret key, this can, for example, take place through a client server architecture)\n",
    "                decrypted_grad_bias = np.array(decrypt(grad_bias, context))\n",
    "                decrypted_grad_thetas = np.array(decrypt(grad_thetas, context))\n",
    "                \n",
    "                # Update parameters\n",
    "                bias = bias - alpha * decrypted_grad_bias\n",
    "                thetas = thetas - alpha * decrypted_grad_thetas\n",
    "\n",
    "        # Log performance\n",
    "        y_pred_train = predict(X_train, bias, thetas)\n",
    "        train_cost = cost(y_train, y_pred_train)\n",
    "        train_r2 = r2_score(y_train, y_pred_train)\n",
    "        \n",
    "        hist[\"train_cost\"].append(train_cost)\n",
    "        hist[\"train_r2\"].append(train_r2)\n",
    "        \n",
    "        if epoch % display_every == 0:\n",
    "            print(f\"Epoch {epoch} - cost: {train_cost:.2f} - r2: {train_r2:.4f}\")\n",
    "        \n",
    "    return bias, thetas, hist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the training of the linear regression with reading from the file is executed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_taken = 10000\n",
    "batch_size = 100\n",
    "\n",
    "alpha = 0.01\n",
    "num_epochs = 6\n",
    "\n",
    "# measure time\n",
    "t_start = time()\n",
    "# measure resource usage\n",
    "mem_usage = psutil.Process().memory_info().rss\n",
    "enc_bias, enc_thetas, hist_rent_enc = enc_fit_minibatch_readfile(X_train_rents[:len_taken], y_train_rents[:len_taken], alpha, num_epochs, batch_size, \"enc_dataframe.bin\", public_context, context)\n",
    "mem_usage_end = psutil.Process().memory_info().rss\n",
    "\n",
    "# Calculate the differences\n",
    "mem_diff = mem_usage_end - mem_usage\n",
    "t_end = time()\n",
    "print(f\"Training of the Linear Regression took {int(t_end - t_start)} seconds\")\n",
    "print(f\"Memory usage difference: {mem_diff} bytes\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
